{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100a17c-4076-4e2a-b9fb-2b26c0249063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This project uses the CREMA-D dataset (you can downlaod it following the instructions at https://github.com/CheyneyComputerScience/CREMA-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "361faef2-ba18-4520-9fe1-6081e53a6c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Locate the folder that contains all the audio file\n",
    "cwd = os.getcwd() \n",
    "audio_path = os.path.join(cwd, \"AudioWAV\")\n",
    "audio_wav = [f for f in os.listdir(audio_path) if f.lower().endswith('.wav')]\n",
    "# Emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41569928-ec11-4445-8ec0-aa54a87a47b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 174 # Max length of audio changable\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for wav_files in audio_wav:\n",
    "    # waveform is audio time series (Amplitude over time)\n",
    "    # sr is sampling rate, number of samples per sec (Hz)\n",
    "\n",
    "    path = os.path.join(audio_path, wav_files)\n",
    "    \n",
    "    emotion_code = wav_files.split(\"_\")[2] # Getting what emotion the file is getting\n",
    "    waveform, sr = librosa.load(path, sr = 22050) # 22050 used everything and saves space\n",
    "\n",
    "    # Converting the wav file into mel_spec\n",
    "    mel_spec = librosa.feature.melspectrogram(y = waveform, sr = sr, n_mels = 128)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec, ref = np.max)\n",
    "    \n",
    "    # Used to make sure everything is the same size\n",
    "    if log_mel_spec.shape[1] < MAX_LEN:\n",
    "        pad_width = MAX_LEN - log_mel_spec.shape[1]\n",
    "        log_mel_spec = np.pad(log_mel_spec, pad_width=((0, 0), (0, pad_width)), mode = 'constant')\n",
    "    else:\n",
    "        log_mel_spec = log_mel_spec[:, :MAX_LEN]\n",
    "\n",
    "        \n",
    "    log_mel_spec = log_mel_spec[..., np.newaxis] # Adds a channel (gray scale) for training\n",
    "\n",
    "    # Appending into X y, \n",
    "    X.append(log_mel_spec)\n",
    "    y.append(emotion_code)    \n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ac7540-5a93-4f6e-94b4-d370724195b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, optimizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from sklearn.model_selection import train_test_split # Splitting 70/30 \n",
    "# from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "304c3843-4d18-4855-8b81-ff8c7a0bd7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We have X and y time to split it in 70/30\n",
    "\n",
    "# Encoding into 0,1,2,3,4,5\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size = 0.3, # 30% is to test it\n",
    "    stratify = y_encoded,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Normalizing\n",
    "min_val = np.min(X_train)\n",
    "max_val = np.max(X_train)\n",
    "X_train = (X_train - min_val) / (max_val - min_val)\n",
    "X_val = (X_val - min_val) / (max_val - min_val)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b38eb7-85ed-48dd-ba44-94f7317f0ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Base model used for training (Added dropout to make sure it won't overfit and make more generalize learning)\n",
    "# This is not that good and only achieved 47% validation accuracy\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = \"relu\", input_shape = (128, MAX_LEN, 1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = \"relu\"))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(layers.Dense(6, activation = \"softmax\")) \n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 20, \n",
    "    validation_data = (X_val, y_val),\n",
    "    verbose = 1 \n",
    ")\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6c5b2e6d-6d0b-4d8c-a864-165bbace8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d33bcd58-347c-47e5-9098-6e65beda33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model once you finish training\n",
    "# model.save(\"insertname.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72791e1d-9c7d-4e7c-98f3-4dd6505eed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used if wanting to continue training from a saved state\n",
    "\n",
    "\n",
    "# Choose the model file to load\n",
    "model = load_model('emotion_model_fix.keras')\n",
    "\n",
    "previous_epochs = 80 # Previous amount of epoch\n",
    "total_epochs = 90 # Put how much further you want to train it to\n",
    "# More training\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = total_epochs,  \n",
    "    validation_data = (X_val, y_val),\n",
    "    initial_epoch = previous_epochs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76e216-5ee9-40f8-9132-bc2e99f79816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but with some guassian noise added to the input\n",
    "\n",
    "# Simply adding some noises into the input\n",
    "data_augmentation = models.Sequential([\n",
    "    layers.GaussianNoise(0.02),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "MAX_LEN = 174 \n",
    "\n",
    "model = models.Sequential([\n",
    "    Input(shape=(128, MAX_LEN, 1)),\n",
    "    data_augmentation,\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), padding = \"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, (3, 3), padding = \"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = \"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(6, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizers.Adam(learning_rate = 0.0001), loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3091224-49ed-4221-9f79-2a3352510d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data augmentation pipeline...\n",
      "Defining the ResNet-style model...\n",
      "Compiling the model...\n",
      "Setting up callbacks...\n",
      "Starting training with ResNet model...\n",
      "Epoch 1/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.3258 - loss: 1.6535\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17062, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 417ms/step - accuracy: 0.3260 - loss: 1.6530 - val_accuracy: 0.1706 - val_loss: 7.3195 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.3880 - loss: 1.4694\n",
      "Epoch 2: val_accuracy improved from 0.17062 to 0.23735, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 403ms/step - accuracy: 0.3880 - loss: 1.4694 - val_accuracy: 0.2373 - val_loss: 4.3412 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.4257 - loss: 1.4371\n",
      "Epoch 3: val_accuracy did not improve from 0.23735\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 378ms/step - accuracy: 0.4257 - loss: 1.4371 - val_accuracy: 0.2284 - val_loss: 2.0752 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.4253 - loss: 1.4252\n",
      "Epoch 4: val_accuracy improved from 0.23735 to 0.33274, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 388ms/step - accuracy: 0.4253 - loss: 1.4250 - val_accuracy: 0.3327 - val_loss: 1.7269 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.4378 - loss: 1.3681\n",
      "Epoch 5: val_accuracy did not improve from 0.33274\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 389ms/step - accuracy: 0.4379 - loss: 1.3681 - val_accuracy: 0.1787 - val_loss: 3.2123 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.4759 - loss: 1.3428\n",
      "Epoch 6: val_accuracy did not improve from 0.33274\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 393ms/step - accuracy: 0.4758 - loss: 1.3428 - val_accuracy: 0.2790 - val_loss: 1.8276 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.4789 - loss: 1.3208\n",
      "Epoch 7: val_accuracy did not improve from 0.33274\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 396ms/step - accuracy: 0.4789 - loss: 1.3208 - val_accuracy: 0.2875 - val_loss: 5.4430 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.4836 - loss: 1.2993\n",
      "Epoch 8: val_accuracy improved from 0.33274 to 0.39901, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 393ms/step - accuracy: 0.4837 - loss: 1.2993 - val_accuracy: 0.3990 - val_loss: 1.5508 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.4938 - loss: 1.2859\n",
      "Epoch 9: val_accuracy did not improve from 0.39901\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 383ms/step - accuracy: 0.4938 - loss: 1.2858 - val_accuracy: 0.2754 - val_loss: 2.2376 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.5143 - loss: 1.2551\n",
      "Epoch 10: val_accuracy did not improve from 0.39901\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 382ms/step - accuracy: 0.5143 - loss: 1.2551 - val_accuracy: 0.2942 - val_loss: 3.0876 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.5057 - loss: 1.2465\n",
      "Epoch 11: val_accuracy did not improve from 0.39901\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 384ms/step - accuracy: 0.5057 - loss: 1.2466 - val_accuracy: 0.2441 - val_loss: 5.8689 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.5341 - loss: 1.2305\n",
      "Epoch 12: val_accuracy did not improve from 0.39901\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 371ms/step - accuracy: 0.5341 - loss: 1.2305 - val_accuracy: 0.3309 - val_loss: 2.3518 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.5378 - loss: 1.2046\n",
      "Epoch 13: val_accuracy improved from 0.39901 to 0.43977, saving model to resnet_model_best.keras\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 378ms/step - accuracy: 0.5378 - loss: 1.2045 - val_accuracy: 0.4398 - val_loss: 1.5760 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.5561 - loss: 1.1598\n",
      "Epoch 14: val_accuracy did not improve from 0.43977\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 429ms/step - accuracy: 0.5562 - loss: 1.1596 - val_accuracy: 0.2311 - val_loss: 3.8567 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5802 - loss: 1.1036\n",
      "Epoch 15: val_accuracy improved from 0.43977 to 0.50605, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 426ms/step - accuracy: 0.5802 - loss: 1.1035 - val_accuracy: 0.5060 - val_loss: 1.3199 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.5838 - loss: 1.0952\n",
      "Epoch 16: val_accuracy improved from 0.50605 to 0.58218, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 408ms/step - accuracy: 0.5838 - loss: 1.0952 - val_accuracy: 0.5822 - val_loss: 1.1099 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.5867 - loss: 1.0623\n",
      "Epoch 17: val_accuracy did not improve from 0.58218\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 420ms/step - accuracy: 0.5867 - loss: 1.0623 - val_accuracy: 0.3426 - val_loss: 1.9678 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.6002 - loss: 1.0691\n",
      "Epoch 18: val_accuracy did not improve from 0.58218\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 425ms/step - accuracy: 0.6002 - loss: 1.0691 - val_accuracy: 0.2647 - val_loss: 8.0262 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.6145 - loss: 1.0386\n",
      "Epoch 19: val_accuracy improved from 0.58218 to 0.62069, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 426ms/step - accuracy: 0.6144 - loss: 1.0387 - val_accuracy: 0.6207 - val_loss: 1.0264 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.6173 - loss: 1.0202\n",
      "Epoch 20: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 431ms/step - accuracy: 0.6173 - loss: 1.0202 - val_accuracy: 0.4098 - val_loss: 1.6248 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.6192 - loss: 1.0146\n",
      "Epoch 21: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 436ms/step - accuracy: 0.6192 - loss: 1.0146 - val_accuracy: 0.4398 - val_loss: 1.5879 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.6159 - loss: 1.0233\n",
      "Epoch 22: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 439ms/step - accuracy: 0.6159 - loss: 1.0233 - val_accuracy: 0.6010 - val_loss: 1.0603 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.6276 - loss: 0.9999\n",
      "Epoch 23: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 438ms/step - accuracy: 0.6276 - loss: 0.9999 - val_accuracy: 0.4241 - val_loss: 1.6446 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.6392 - loss: 0.9895\n",
      "Epoch 24: val_accuracy did not improve from 0.62069\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 440ms/step - accuracy: 0.6392 - loss: 0.9895 - val_accuracy: 0.2306 - val_loss: 3.4033 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.6275 - loss: 0.9898\n",
      "Epoch 25: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 438ms/step - accuracy: 0.6276 - loss: 0.9896 - val_accuracy: 0.6158 - val_loss: 1.0109 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.6556 - loss: 0.9256\n",
      "Epoch 26: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 466ms/step - accuracy: 0.6556 - loss: 0.9256 - val_accuracy: 0.6122 - val_loss: 1.0409 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.6599 - loss: 0.9198\n",
      "Epoch 27: val_accuracy improved from 0.62069 to 0.62382, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 447ms/step - accuracy: 0.6599 - loss: 0.9198 - val_accuracy: 0.6238 - val_loss: 1.0101 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6652 - loss: 0.9067\n",
      "Epoch 28: val_accuracy improved from 0.62382 to 0.62562, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 447ms/step - accuracy: 0.6652 - loss: 0.9069 - val_accuracy: 0.6256 - val_loss: 0.9846 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6728 - loss: 0.9091\n",
      "Epoch 29: val_accuracy improved from 0.62562 to 0.63368, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 446ms/step - accuracy: 0.6727 - loss: 0.9091 - val_accuracy: 0.6337 - val_loss: 1.0022 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.6559 - loss: 0.9282\n",
      "Epoch 30: val_accuracy improved from 0.63368 to 0.64666, saving model to resnet_model_best.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 459ms/step - accuracy: 0.6560 - loss: 0.9282 - val_accuracy: 0.6467 - val_loss: 0.9680 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.6610 - loss: 0.9100\n",
      "Epoch 31: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 432ms/step - accuracy: 0.6611 - loss: 0.9100 - val_accuracy: 0.5943 - val_loss: 1.0794 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.6634 - loss: 0.9151\n",
      "Epoch 32: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 413ms/step - accuracy: 0.6634 - loss: 0.9151 - val_accuracy: 0.6153 - val_loss: 1.0342 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.6733 - loss: 0.9004\n",
      "Epoch 33: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 424ms/step - accuracy: 0.6733 - loss: 0.9003 - val_accuracy: 0.6301 - val_loss: 0.9920 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.6626 - loss: 0.9122\n",
      "Epoch 34: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 430ms/step - accuracy: 0.6627 - loss: 0.9121 - val_accuracy: 0.6220 - val_loss: 1.0208 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.6842 - loss: 0.8832\n",
      "Epoch 35: val_accuracy did not improve from 0.64666\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 438ms/step - accuracy: 0.6842 - loss: 0.8833 - val_accuracy: 0.6202 - val_loss: 1.0123 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.6710 - loss: 0.8848\n",
      "Epoch 36: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 415ms/step - accuracy: 0.6710 - loss: 0.8848 - val_accuracy: 0.6368 - val_loss: 0.9857 - learning_rate: 8.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.6759 - loss: 0.8717\n",
      "Epoch 37: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 419ms/step - accuracy: 0.6759 - loss: 0.8718 - val_accuracy: 0.6314 - val_loss: 0.9917 - learning_rate: 8.0000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.6847 - loss: 0.8684\n",
      "Epoch 38: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 428ms/step - accuracy: 0.6847 - loss: 0.8685 - val_accuracy: 0.6341 - val_loss: 0.9695 - learning_rate: 8.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.6760 - loss: 0.8753\n",
      "Epoch 39: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 434ms/step - accuracy: 0.6760 - loss: 0.8752 - val_accuracy: 0.6310 - val_loss: 0.9955 - learning_rate: 8.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.6792 - loss: 0.8678\n",
      "Epoch 40: val_accuracy did not improve from 0.64666\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 434ms/step - accuracy: 0.6792 - loss: 0.8679 - val_accuracy: 0.6355 - val_loss: 0.9795 - learning_rate: 8.0000e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.6818 - loss: 0.8673\n",
      "Epoch 41: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 438ms/step - accuracy: 0.6817 - loss: 0.8673 - val_accuracy: 0.6323 - val_loss: 0.9893 - learning_rate: 1.6000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.6901 - loss: 0.8613\n",
      "Epoch 42: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 443ms/step - accuracy: 0.6901 - loss: 0.8613 - val_accuracy: 0.6310 - val_loss: 0.9928 - learning_rate: 1.6000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.6853 - loss: 0.8452\n",
      "Epoch 43: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 441ms/step - accuracy: 0.6853 - loss: 0.8453 - val_accuracy: 0.6301 - val_loss: 0.9927 - learning_rate: 1.6000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.6725 - loss: 0.8810\n",
      "Epoch 44: val_accuracy did not improve from 0.64666\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 449ms/step - accuracy: 0.6725 - loss: 0.8809 - val_accuracy: 0.6305 - val_loss: 0.9872 - learning_rate: 1.6000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.6772 - loss: 0.8805\n",
      "Epoch 45: val_accuracy did not improve from 0.64666\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 451ms/step - accuracy: 0.6773 - loss: 0.8804 - val_accuracy: 0.6296 - val_loss: 0.9882 - learning_rate: 1.6000e-06\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Model with highest validation accuracy\n",
    "# Res-Net + SpecAugment\n",
    "\n",
    "\n",
    "# This is used to mask frequency for more generalization to prevent overfitting\n",
    "class FrequencyMask(layers.Layer):\n",
    "    def __init__(self, max_mask_size = 16, **kwargs):\n",
    "        super(FrequencyMask, self).__init__(**kwargs)\n",
    "        self.max_mask_size = max_mask_size\n",
    "    def call(self, inputs, training=None):\n",
    "        if not training:\n",
    "            return inputs\n",
    "        num_mels = tf.shape(inputs)[1]\n",
    "        mask_size = tf.random.uniform(shape=[], minval=0, maxval=self.max_mask_size, dtype=tf.int32)\n",
    "        mask_start = tf.random.uniform(shape=[], minval=0, maxval=num_mels - mask_size, dtype=tf.int32)\n",
    "        mask_range = tf.range(num_mels, dtype=tf.int32)\n",
    "        mask_condition = (mask_range < mask_start) | (mask_range >= mask_start + mask_size)\n",
    "        mask = tf.cast(mask_condition, inputs.dtype)\n",
    "        mask = tf.reshape(mask, (1, num_mels, 1, 1))\n",
    "        return inputs * mask\n",
    "\n",
    "# augment the data\n",
    "data_augmentation = models.Sequential([\n",
    "    layers.GaussianNoise(0.02),\n",
    "    FrequencyMask(max_mask_size=16)\n",
    "], name = \"data_augmentation\")\n",
    "\n",
    "# ResNet training\n",
    "def residual_block(x, filters, strides=(1, 1)):\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main\n",
    "    fx = layers.Conv2D(filters, (3, 3), strides = strides, padding = \"same\")(x)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "    fx = layers.Activation(\"relu\")(fx)\n",
    "\n",
    "    fx = layers.Conv2D(filters, (3, 3), padding = \"same\")(fx)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "\n",
    "    # Shortcut \n",
    "    if strides != (1, 1) or x.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), strides=strides, padding = \"same\")(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    # Shortcut -> Main\n",
    "    output = layers.Add()([fx, shortcut])\n",
    "    output = layers.Activation(\"relu\")(output)\n",
    "    return output\n",
    "\n",
    "# Max Length as defined above \n",
    "MAX_LEN = 174 \n",
    "\n",
    "inputs = Input(shape=(128, MAX_LEN, 1))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Features\n",
    "x = layers.Conv2D(32, (7, 7), strides=(2, 2), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "# Skips\n",
    "x = residual_block(x, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "\n",
    "x = residual_block(x, filters=128, strides=(2, 2))\n",
    "x = residual_block(x, filters=128)\n",
    "\n",
    "# Classify\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation = \"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer = optimizers.Adam(learning_rate = 0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Checkpoint to save the best model\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath = \"best_model.keras\",\n",
    "    monitor = \"val_accuracy\",\n",
    "    mode = \"max\",\n",
    "    save_best_only = True,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Reduce the learning rate if no progress is made in val acc\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = \"val_loss\",\n",
    "    factor = 0.2,\n",
    "    patience = 5, # The amount of times before changing lr\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Stop training after a while if no progress is made\n",
    "stop_early = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    patience = 15, # If after 15 epoch no progress then stop\n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 100,\n",
    "    validation_data = (X_val, y_val),\n",
    "    callbacks = [\n",
    "        model_checkpoint, \n",
    "        reduce_lr, \n",
    "        stop_early\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23d1565a-4393-4a64-b09b-13cfae517423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'anger',\n",
       " '1': 'disgust',\n",
       " '2': 'fear',\n",
       " '3': 'happy',\n",
       " '4': 'neutral',\n",
       " '5': 'sad'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 0 is ang\n",
    "# 4 is neu\n",
    "# 1 is Dis\n",
    "# 5 is sad\n",
    "# 2 is Fea\n",
    "# 3 is happy\n",
    "\n",
    "{\n",
    "  \"0\": \"anger\",\n",
    "  \"1\": \"disgust\",\n",
    "  \"2\": \"fear\",\n",
    "  \"3\": \"happy\",\n",
    "  \"4\": \"neutral\",\n",
    "  \"5\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04652f50-ba13-496e-860c-f99c8f7b3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-80.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "min_val = np.min(X_train)\n",
    "max_val = np.max(X_train)\n",
    "\n",
    "print(min_val)\n",
    "print(max_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
